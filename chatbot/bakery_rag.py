import json
import os
from typing import List, Dict, Optional
import numpy as np
from sentence_transformers import SentenceTransformer
import chromadb
from chromadb.config import Settings
from openai import OpenAI
from tqdm import tqdm

# ----------------- 0. ì„¤ì • -----------------
DATA_FILE = "./chatbot/dessert.json"
VECTOR_DB_PATH = "./bakery_vectordb"
COLLECTION_NAME = "bakery_collection"

# ì„ë² ë”© ëª¨ë¸ ì„¤ì • (í•œêµ­ì–´ ìµœì í™”)
EMBEDDING_MODEL = "jhgan/ko-sroberta-multitask"  # í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸

# OpenAI API ì„¤ì • (í•„ìš”ì‹œ)
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "your-api-key-here")

# ê²€ìƒ‰ ì„¤ì •
TOP_K_RESULTS = 5  # ìƒìœ„ Kê°œ ê²°ê³¼ ë°˜í™˜
SIMILARITY_THRESHOLD = 0.5  # ìœ ì‚¬ë„ ì„ê³„ê°’
# ------------------------------------------

class BakeryRAGSystem:
    """
    ë¹µì§‘ ì¶”ì²œì„ ìœ„í•œ RAG ì‹œìŠ¤í…œ
    - ë²¡í„° DB êµ¬ì¶• ë° ê´€ë¦¬
    - í‚¤ì›Œë“œ ê¸°ë°˜ ìœ ì‚¬ë„ ê²€ìƒ‰
    - LLM ê¸°ë°˜ ìì—°ì–´ ì¶”ì²œ
    """
    
    def __init__(self, embedding_model_name: str = EMBEDDING_MODEL):
        """
        RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        
        Args:
            embedding_model_name: ì„ë² ë”© ëª¨ë¸ ì´ë¦„
        """
        print("ğŸš€ ë¹µì§‘ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        
        # 1. ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
        print(f"ğŸ“¦ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ: {embedding_model_name}")
        self.embedding_model = SentenceTransformer(embedding_model_name)
        
        # 2. ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        print(f"ğŸ’¾ ë²¡í„° DB ì´ˆê¸°í™”: {VECTOR_DB_PATH}")
        self.client = chromadb.PersistentClient(path=VECTOR_DB_PATH)
        
        # 3. ì»¬ë ‰ì…˜ ìƒì„± ë˜ëŠ” ë¡œë“œ
        try:
            self.collection = self.client.get_collection(name=COLLECTION_NAME)
            print(f"âœ… ê¸°ì¡´ ì»¬ë ‰ì…˜ ë¡œë“œ: {COLLECTION_NAME}")
        except:
            self.collection = self.client.create_collection(
                name=COLLECTION_NAME,
                metadata={"description": "ë¹µì§‘ ì •ë³´ ë²¡í„° DB"}
            )
            print(f"âœ… ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±: {COLLECTION_NAME}")
        
        print("âœ… RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!\n")
    
    def create_bakery_text(self, bakery: Dict) -> str:
        """
        ë¹µì§‘ ì •ë³´ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ì„ë² ë”©ìš©)
        
        Args:
            bakery: ë¹µì§‘ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        
        Returns:
            ì„ë² ë”©ìš© í…ìŠ¤íŠ¸
        """
        # ìƒˆ JSON êµ¬ì¡°ì— ë§ì¶˜ í•„ë“œëª…
        place_name = bakery.get('name', 'ì•Œ ìˆ˜ ì—†ìŒ')
        keywords = bakery.get('keywords', [])
        category = bakery.get('category', 'ë² ì´ì»¤ë¦¬')
        
        # ì£¼ì†Œ ì •ë³´ (ë„ë¡œëª… ìš°ì„ , ì—†ìœ¼ë©´ ì§€ë²ˆ)
        address = bakery.get('road_address', bakery.get('jibun_address', 'ì£¼ì†Œ ì •ë³´ ì—†ìŒ'))
        
        # êµ¬ ì •ë³´
        district = bakery.get('district', '')
        
        # ì—°ë½ì²˜
        phone = bakery.get('phone', '')
        
        # í‰ì  ì •ë³´ (ratingì´ dictì¸ ê²½ìš°)
        rating_info = bakery.get('rating', {})
        if isinstance(rating_info, dict):
            naver_rate = rating_info.get('naver_rate', '0')
            kakao_rate = rating_info.get('kakao_rate', '0')
            rating_text = f"ë„¤ì´ë²„ {naver_rate}ì , ì¹´ì¹´ì˜¤ {kakao_rate}ì "
        else:
            rating_text = f"{rating_info}ì "
        
        # ë¦¬ë·° í‚¤ì›Œë“œ ì •ë³´
        review_keywords = bakery.get('review_keywords', [])
        review_kw_text = ", ".join([kw['keyword'].strip('"') for kw in review_keywords[:5]])
        
        # ëŒ€ê¸° ì‹œê°„ ì •ë³´ (waiting_prediction)
        waiting_info = bakery.get('waiting_prediction', {})
        wait_text = ""
        if waiting_info:
            overall_stats = waiting_info.get('overall_stats', {})
            avg_wait = overall_stats.get('average_minutes', 0)
            if avg_wait > 0:
                wait_text = f"í‰ê·  ëŒ€ê¸° ì‹œê°„: {avg_wait}ë¶„"
        
        # ì„ë² ë”©ìš© í…ìŠ¤íŠ¸ ìƒì„± (í‚¤ì›Œë“œì™€ íŠ¹ì§• ì¤‘ì‹¬)
        text_parts = [
            f"ë¹µì§‘ ì´ë¦„: {place_name}",
            f"ì¹´í…Œê³ ë¦¬: {category}",
        ]
        
        if district:
            text_parts.append(f"ìœ„ì¹˜: ëŒ€ì „ {district}")
        
        if keywords:
            text_parts.append(f"íŠ¹ì§• í‚¤ì›Œë“œ: {', '.join(keywords)}")
        
        if review_kw_text:
            text_parts.append(f"ê³ ê° í‰ê°€: {review_kw_text}")
        
        if wait_text:
            text_parts.append(wait_text)
        
        text_parts.extend([
            f"ì£¼ì†Œ: {address}",
            f"í‰ì : {rating_text}"
        ])
        
        return "\n".join(text_parts)
    
    def create_bakery_metadata(self, bakery: Dict) -> Dict:
        """
        ë¹µì§‘ ì •ë³´ë¥¼ ë©”íƒ€ë°ì´í„°ë¡œ ë³€í™˜ (ê²€ìƒ‰ ê²°ê³¼ìš©)
        
        Args:
            bakery: ë¹µì§‘ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        
        Returns:
            ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        """
        # ìƒˆ JSON êµ¬ì¡°ì— ë§ì¶˜ í•„ë“œëª…
        place_name = bakery.get('name', 'ì•Œ ìˆ˜ ì—†ìŒ')
        address = bakery.get('road_address', bakery.get('jibun_address', 'ì£¼ì†Œ ì •ë³´ ì—†ìŒ'))
        phone = bakery.get('phone', 'ì „í™”ë²ˆí˜¸ ì—†ìŒ')
        category = bakery.get('category', 'ë² ì´ì»¤ë¦¬')
        district = bakery.get('district', '')
        url = bakery.get('url', '')
        
        # í‰ì  ì •ë³´
        rating_info = bakery.get('rating', {})
        if isinstance(rating_info, dict):
            naver_rate = rating_info.get('naver_rate', '0')
            kakao_rate = rating_info.get('kakao_rate', '0')
            rating_str = f"ë„¤ì´ë²„ {naver_rate}, ì¹´ì¹´ì˜¤ {kakao_rate}"
        else:
            rating_str = str(rating_info)
        
        # í‚¤ì›Œë“œ
        keywords = bakery.get('keywords', [])
        keywords_str = ', '.join(keywords) if keywords else 'ì •ë³´ ì—†ìŒ'
        
        # ë¦¬ë·° í‚¤ì›Œë“œ (ìƒìœ„ 3ê°œ)
        review_keywords = bakery.get('review_keywords', [])
        review_kw_str = ', '.join([kw['keyword'].strip('"') for kw in review_keywords[:3]])
        
        # ì˜ì—…ì‹œê°„ ì •ë³´ (business_hours_rawì—ì„œ ì¶”ì¶œ)
        business_hours = bakery.get('business_hours_raw', 'ì˜ì—…ì‹œê°„ ì •ë³´ ì—†ìŒ')
        
        # ëŒ€ê¸° ì‹œê°„ ì •ë³´
        waiting_info = bakery.get('waiting_prediction', {})
        avg_wait = "ì •ë³´ ì—†ìŒ"
        if waiting_info:
            overall_stats = waiting_info.get('overall_stats', {})
            avg_minutes = overall_stats.get('average_minutes', 0)
            if avg_minutes > 0:
                avg_wait = f"{avg_minutes}ë¶„"
            else:
                avg_wait = "ëŒ€ê¸° ì—†ìŒ"
        
        return {
            'place_name': place_name,
            'address': address,
            'phone': phone,
            'rating': rating_str,
            'keywords': keywords_str,
            'review_keywords': review_kw_str,
            'category': category,
            'district': district,
            'url': url,
            'business_hours': business_hours,
            'avg_waiting_time': avg_wait
        }
    
    def load_and_index_bakeries(self, data_file: str = DATA_FILE, force_reindex: bool = False):
        """
        ë¹µì§‘ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ ë²¡í„° DBì— ì¸ë±ì‹±
        
        Args:
            data_file: ë¹µì§‘ ë°ì´í„° JSON íŒŒì¼ ê²½ë¡œ
            force_reindex: ê¸°ì¡´ ë°ì´í„° ì‚­ì œ í›„ ì¬ì¸ë±ì‹± ì—¬ë¶€
        """
        print(f"\n{'='*60}")
        print("ğŸ“Š ë¹µì§‘ ë°ì´í„° ì¸ë±ì‹± ì‹œì‘")
        print(f"{'='*60}\n")
        
        # ê¸°ì¡´ ë°ì´í„° í™•ì¸
        existing_count = self.collection.count()
        
        if existing_count > 0 and not force_reindex:
            print(f"â„¹ï¸ ì´ë¯¸ {existing_count}ê°œì˜ ë¹µì§‘ì´ ì¸ë±ì‹±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            print("   ì¬ì¸ë±ì‹±í•˜ë ¤ë©´ force_reindex=Trueë¡œ ì„¤ì •í•˜ì„¸ìš”.\n")
            return
        
        if force_reindex and existing_count > 0:
            print(f"ğŸ—‘ï¸ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì¤‘... ({existing_count}ê°œ)")
            self.client.delete_collection(name=COLLECTION_NAME)
            self.collection = self.client.create_collection(
                name=COLLECTION_NAME,
                metadata={"description": "ë¹µì§‘ ì •ë³´ ë²¡í„° DB"}
            )
        
        # 1. ë°ì´í„° ë¡œë“œ
        if not os.path.exists(data_file):
            print(f"âŒ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_file}")
            return
        
        with open(data_file, 'r', encoding='utf-8') as f:
            bakeries = json.load(f)
        
        print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(bakeries)}ê°œ ë¹µì§‘\n")
        
        # 2. ì„ë² ë”© ë° ì¸ë±ì‹±
        print("ğŸ”„ ì„ë² ë”© ë° ë²¡í„° DB ì €ì¥ ì¤‘...\n")
        
        documents = []
        metadatas = []
        ids = []
        
        for idx, bakery in enumerate(tqdm(bakeries, desc="ì„ë² ë”© ìƒì„±")):
            # ì„ë² ë”©ìš© í…ìŠ¤íŠ¸ ìƒì„±
            text = self.create_bakery_text(bakery)
            documents.append(text)
            
            # ë©”íƒ€ë°ì´í„° ìƒì„±
            metadata = self.create_bakery_metadata(bakery)
            metadatas.append(metadata)
            
            # ID ìƒì„±
            ids.append(f"bakery_{idx}")
        
        # ë°°ì¹˜ë¡œ ì„ë² ë”© ìƒì„± (ì†ë„ í–¥ìƒ)
        print("\nğŸ¯ ë²¡í„° ì„ë² ë”© ìƒì„± ì¤‘...")
        embeddings = self.embedding_model.encode(
            documents, 
            show_progress_bar=True,
            batch_size=32
        )
        
        # ChromaDBì— ì €ì¥
        print("\nğŸ’¾ ë²¡í„° DBì— ì €ì¥ ì¤‘...")
        self.collection.add(
            embeddings=embeddings.tolist(),
            documents=documents,
            metadatas=metadatas,
            ids=ids
        )
        
        print(f"\n{'='*60}")
        print(f"âœ… ì¸ë±ì‹± ì™„ë£Œ: {len(bakeries)}ê°œ ë¹µì§‘")
        print(f"{'='*60}\n")
    
    def extract_keywords_from_query(self, query: str) -> List[str]:
        """
        ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨í•œ ë°©ì‹)
        
        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
        
        Returns:
            ì¶”ì¶œëœ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        """
        # ë¹µì§‘ ê´€ë ¨ í‚¤ì›Œë“œ ì‚¬ì „
        keyword_dict = {
            # ë§› ê´€ë ¨
            'ë‹¬ì½¤': 'ë‹¬ì½¤í•œ', 'ë‹¬ë‹¬': 'ë‹¬ì½¤í•œ', 'ë‹¨': 'ë‹¬ì½¤í•œ', 'ë‹¬ì•„': 'ë‹¬ì½¤í•œ',
            'ì§­ì§¤': 'ì§­ì§¤í•œ', 'ì§ ': 'ì§­ì§¤í•œ',
            'ê³ ì†Œ': 'ê³ ì†Œí•œ', 'êµ¬ìˆ˜': 'ê³ ì†Œí•œ',
            'ë°”ì‚­': 'ë°”ì‚­í•œ', 'ë°”ì‚­ë°”ì‚­': 'ë°”ì‚­í•œ', 'ë°”ì‚­ë°”ì‚­í•œ': 'ë°”ì‚­í•œ',
            'ë¶€ë“œëŸ¬': 'ë¶€ë“œëŸ¬ìš´', 'ì´‰ì´‰': 'ì´‰ì´‰í•œ',
            'ì«„ê¹ƒ': 'ì«„ê¹ƒí•œ', 'ì«€ë“': 'ì«€ë“í•œ',
            'ìƒˆì½¤': 'ìƒˆì½¤í•œ', 'ìƒí¼': 'ìƒí¼í•œ',
            
            # ë¹µ ì¢…ë¥˜
            'í¬ë¡œì™€ìƒ': 'í¬ë¡œì™€ìƒ', 'í¬ë£¨ì•„ìƒ': 'í¬ë¡œì™€ìƒ', 'í¬ì™€ìƒ': 'í¬ë¡œì™€ìƒ',
            'ë°”ê²ŒíŠ¸': 'ë°”ê²ŒíŠ¸', 'ë¹µ': 'ì‹ë¹µ', 'ì‹ë¹µ': 'ì‹ë¹µ',
            'ë² ì´ê¸€': 'ë² ì´ê¸€', 'ë„ë„›': 'ë„ë„›',
            'íƒ€ë¥´íŠ¸': 'íƒ€ë¥´íŠ¸', 'ì—ê·¸íƒ€ë¥´íŠ¸': 'ì—ê·¸íƒ€ë¥´íŠ¸', 'ì—ê·¸íƒ€íŠ¸': 'ì—ê·¸íƒ€ë¥´íŠ¸',
            'ë§ˆì¹´ë¡±': 'ë§ˆì¹´ë¡±', 'ìŠ¤ì½˜': 'ìŠ¤ì½˜',
            'ì¹´ìŠ¤í…Œë¼': 'ì¹´ìŠ¤í…Œë¼', 'í˜ìŠ¤ì¸„ë¦¬': 'í˜ìŠ¤ì¸„ë¦¬',
            'ì†Œê¸ˆë¹µ': 'ì†Œê¸ˆë¹µ', 'ì¹˜ì•„ë°”íƒ€': 'ì¹˜ì•„ë°”íƒ€',
            
            # íŠ¹ì§•
            'ì‹ ì„ ': 'ì‹ ì„ í•œ', 'ê°“êµ¬ìš´': 'ê°“ êµ¬ìš´', 'ê°“ êµ¬ìš´': 'ê°“ êµ¬ìš´',
            'ìˆ˜ì œ': 'ìˆ˜ì œ', 'ì‹œê·¸ë‹ˆì²˜': 'ì‹œê·¸ë‹ˆì²˜',
            'ê±´ê°•': 'ê±´ê°•ë¹µ', 'ìœ ê¸°ë†': 'ìœ ê¸°ë†',
            
            # ì§€ì—­ (ëŒ€ì „)
            'ìœ ì„±': 'ìœ ì„±êµ¬', 'ì„œêµ¬': 'ì„œêµ¬', 'ë™êµ¬': 'ë™êµ¬', 'ì¤‘êµ¬': 'ì¤‘êµ¬', 'ëŒ€ë•': 'ëŒ€ë•êµ¬',
        }
        
        extracted = set()
        query_lower = query.lower()
        
        for key, standard_keyword in keyword_dict.items():
            if key in query_lower:
                extracted.add(standard_keyword)
        
        return list(extracted)
    
    def search(self, query: str, top_k: int = TOP_K_RESULTS) -> List[Dict]:
        """
        ìì—°ì–´ ì§ˆë¬¸ìœ¼ë¡œ ë¹µì§‘ ê²€ìƒ‰
        
        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸ (ì˜ˆ: "ë°”ì‚­í•œ í¬ë¡œì™€ìƒì´ ë§›ìˆëŠ” ë¹µì§‘ ì¶”ì²œí•´ì¤˜")
            top_k: ë°˜í™˜í•  ìƒìœ„ ê²°ê³¼ ìˆ˜
        
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        print(f"\nğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: {query}")
        
        # 1. í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = self.extract_keywords_from_query(query)
        if keywords:
            print(f"ğŸ“Œ ì¶”ì¶œëœ í‚¤ì›Œë“œ: {', '.join(keywords)}")
            # í‚¤ì›Œë“œë¥¼ ì¿¼ë¦¬ì— ì¶”ê°€í•˜ì—¬ ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ
            enhanced_query = f"{query} {' '.join(keywords)}"
        else:
            enhanced_query = query
        
        # 2. ì¿¼ë¦¬ ì„ë² ë”©
        query_embedding = self.embedding_model.encode([enhanced_query])[0]
        
        # 3. ìœ ì‚¬ë„ ê²€ìƒ‰
        results = self.collection.query(
            query_embeddings=[query_embedding.tolist()],
            n_results=top_k,
            include=['documents', 'metadatas', 'distances']
        )
        
        # 4. ê²°ê³¼ í¬ë§·íŒ… (ìƒˆ í•„ë“œ ì¶”ê°€)
        formatted_results = []
        if results['ids'] and len(results['ids'][0]) > 0:
            for i in range(len(results['ids'][0])):
                similarity = 1 - results['distances'][0][i]  # ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜
                
                metadata = results['metadatas'][0][i]
                result = {
                    'place_name': metadata['place_name'],
                    'address': metadata['address'],
                    'phone': metadata['phone'],
                    'rating': metadata['rating'],
                    'keywords': metadata['keywords'],
                    'review_keywords': metadata.get('review_keywords', ''),
                    'district': metadata.get('district', ''),
                    'url': metadata.get('url', ''),
                    'business_hours': metadata.get('business_hours', 'ì˜ì—…ì‹œê°„ ì •ë³´ ì—†ìŒ'),
                    'avg_waiting_time': metadata.get('avg_waiting_time', 'ì •ë³´ ì—†ìŒ'),
                    'similarity_score': round(similarity, 3),
                    'document': results['documents'][0][i]
                }
                formatted_results.append(result)
        
        return formatted_results
    
    def search_and_display(self, query: str, top_k: int = TOP_K_RESULTS):
        """
        ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥
        
        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            top_k: ë°˜í™˜í•  ìƒìœ„ ê²°ê³¼ ìˆ˜
        """
        results = self.search(query, top_k)
        
        if not results:
            print("\nâš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"\n{'='*60}")
        print(f"âœ¨ ì¶”ì²œ ë¹µì§‘ Top {len(results)}")
        print(f"{'='*60}\n")
        
        for i, result in enumerate(results, 1):
            print(f"ğŸ¥– {i}. {result['place_name']}")
            print(f"   â­ í‰ì : {result['rating']}")
            
            if result['keywords'] and result['keywords'] != 'ì •ë³´ ì—†ìŒ':
                print(f"   ğŸ·ï¸ íŠ¹ì§•: {result['keywords']}")
            
            if result.get('review_keywords'):
                print(f"   ğŸ’¬ ê³ ê°í‰: {result['review_keywords']}")
            
            if result.get('district'):
                print(f"   ğŸ“ ìœ„ì¹˜: ëŒ€ì „ {result['district']}")
            
            print(f"   ğŸ  ì£¼ì†Œ: {result['address']}")
            
            if result['phone'] and result['phone'] != 'ì „í™”ë²ˆí˜¸ ì—†ìŒ':
                print(f"   ğŸ“ ì „í™”: {result['phone']}")
            
            # ëŒ€ê¸° ì‹œê°„ ì •ë³´ í‘œì‹œ
            if result.get('avg_waiting_time') and result['avg_waiting_time'] != 'ì •ë³´ ì—†ìŒ':
                print(f"   â° í‰ê·  ëŒ€ê¸°: {result['avg_waiting_time']}")
            
            print(f"   ğŸ¯ ìœ ì‚¬ë„: {result['similarity_score']}")
            
            if result.get('url'):
                print(f"   ğŸ—ºï¸ ì§€ë„: {result['url']}")
            
            print()
    
    def generate_llm_response(self, query: str, search_results: List[Dict], 
                             use_openai: bool = False) -> str:
        """
        LLMì„ ì‚¬ìš©í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ ì¶”ì²œ ë‹µë³€ ìƒì„±
        
        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            search_results: ê²€ìƒ‰ ê²°ê³¼
            use_openai: OpenAI API ì‚¬ìš© ì—¬ë¶€
        
        Returns:
            LLM ìƒì„± ë‹µë³€
        """
        if not search_results:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” ë¹µì§‘ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ë³´ì‹œê² ì–´ìš”?"
        
        # ê²€ìƒ‰ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        context = "\n\n".join([
            f"ë¹µì§‘ {i+1}: {result['place_name']}\n"
            f"íŠ¹ì§•: {result['keywords']}\n"
            f"í‰ì : {result['rating']}\n"
            f"ìœ„ì¹˜: {result.get('district', '')} {result['address']}\n"
            f"ì „í™”: {result['phone']}\n"
            f"í‰ê·  ëŒ€ê¸°: {result.get('avg_waiting_time', 'ì •ë³´ ì—†ìŒ')}"
            for i, result in enumerate(search_results[:3])  # ìƒìœ„ 3ê°œë§Œ ì‚¬ìš©
        ])
        
        if use_openai and OPENAI_API_KEY != "your-api-key-here":
            # GMS API ì‚¬ìš©
            
            # GMS í”„ë¡ì‹œ ì—”ë“œí¬ì¸íŠ¸ ì„¤ì •
            GMS_BASE_URL = "https://gms.ssafy.io/gmsapi/api.openai.com/v1"
            
            # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹œ base_urlê³¼ api_key ì„¤ì •
            client = OpenAI(
                api_key=OPENAI_API_KEY,  # í™˜ê²½ë³€ìˆ˜ì— ì €ì¥ëœ GMS_KEY ì‚¬ìš©
                base_url=GMS_BASE_URL,   # GMS í”„ë¡ì‹œ ì£¼ì†Œ ì„¤ì •
            )
            
            # ëª¨ë¸ì€ gpt-4.1-nanoë¡œ ìœ ì§€ (GMSì—ì„œ í•´ë‹¹ ëª¨ë¸ì„ ì§€ì›í•œë‹¤ê³  ê°€ì •)
            MODEL_NAME = "gpt-4.1-nano"
            
            prompt = f"""ë‹¹ì‹ ì€ ì¹œì ˆí•œ ë¹µì§‘ ì¶”ì²œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ê²€ìƒ‰ëœ ë¹µì§‘ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ì§ˆë¬¸: {query}

ê²€ìƒ‰ëœ ë¹µì§‘ ì •ë³´:
{context}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ë¹µì§‘ì„ ì¶”ì²œí•˜ëŠ” ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”. 
ê° ë¹µì§‘ì˜ íŠ¹ì§•ê³¼ ì¥ì ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”."""
            prompt = prompt.encode('utf-8', 'ignore').decode('utf-8')

            try:
                print("Debug checkpoint 1")
                response = client.chat.completions.create(
                    model="gpt-4.1-nano",
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹œì ˆí•œ ë¹µì§‘ ì¶”ì²œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.7,
                    max_tokens=500
                )
                print("Debug checkpoint 2")
                return response.choices[0].message.content
            except Exception as e:
                print(f"âš ï¸ OpenAI API ì˜¤ë¥˜: {e}")
                # í´ë°±: í…œí”Œë¦¿ ê¸°ë°˜ ì‘ë‹µ
        
        # í…œí”Œë¦¿ ê¸°ë°˜ ì‘ë‹µ (OpenAI ë¯¸ì‚¬ìš© ì‹œ)
        response = f"'{query}'ì— ëŒ€í•œ ì¶”ì²œ ë¹µì§‘ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!\n\n"
        
        for i, result in enumerate(search_results[:3], 1):
            response += f"{i}. **{result['place_name']}** ({result['rating']})\n"
            if result['keywords'] and result['keywords'] != 'ì •ë³´ ì—†ìŒ':
                response += f"   - íŠ¹ì§•: {result['keywords']}\n"
            if result.get('district'):
                response += f"   - ìœ„ì¹˜: ëŒ€ì „ {result['district']}\n"
            response += f"   - ì£¼ì†Œ: {result['address']}\n"
            if result.get('avg_waiting_time') and result['avg_waiting_time'] != 'ì •ë³´ ì—†ìŒ':
                response += f"   - í‰ê·  ëŒ€ê¸°: {result['avg_waiting_time']}\n"
            if i < len(search_results[:3]):
                response += "\n"
        
        response += "\nìœ„ ë¹µì§‘ë“¤ì„ ì¶”ì²œë“œë¦½ë‹ˆë‹¤! ë” ìì„¸í•œ ì •ë³´ê°€ í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”. ğŸ˜Š"
        
        return response
    
    def chat(self, query: str, use_llm: bool = True, use_openai: bool = False):
        """
        ëŒ€í™”í˜• ë¹µì§‘ ì¶”ì²œ (RAG ì „ì²´ íŒŒì´í”„ë¼ì¸)
        
        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            use_llm: LLM ë‹µë³€ ìƒì„± ì—¬ë¶€
            use_openai: OpenAI API ì‚¬ìš© ì—¬ë¶€
        """
        # 1. ê²€ìƒ‰
        results = self.search(query, top_k=TOP_K_RESULTS)
        
        # 2. ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥
        self.search_and_display(query, top_k=TOP_K_RESULTS)
        
        # 3. LLM ë‹µë³€ ìƒì„± (ì„ íƒ)
        if use_llm:
            print(f"{'='*60}")
            print("ğŸ¤– AI ì¶”ì²œ ë‹µë³€")
            print(f"{'='*60}\n")
            response = self.generate_llm_response(query, results, use_openai)
            print(response)
            print()

# ----------------- ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ -----------------

def main():
    """
    ë¹µì§‘ RAG ì‹œìŠ¤í…œ ë©”ì¸ ì‹¤í–‰
    """
    print(f"\n{'='*60}")
    print("ğŸ ë¹µì§‘ ì¶”ì²œ RAG ì‹œìŠ¤í…œ")
    print(f"{'='*60}\n")
    
    # 1. RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    rag = BakeryRAGSystem()
    
    # 2. ë°ì´í„° ì¸ë±ì‹± (ìµœì´ˆ 1íšŒ ì‹¤í–‰)
    rag.load_and_index_bakeries(force_reindex=False)
    
    # 3. ì˜ˆì‹œ ê²€ìƒ‰
    print("\n" + "="*60)
    print("ğŸ’¡ ì‚¬ìš© ì˜ˆì‹œ")
    print("="*60 + "\n")
    
    example_queries = [
        "ë°”ì‚­í•œ í¬ë¡œì™€ìƒì´ ë§›ìˆëŠ” ë¹µì§‘ ì¶”ì²œí•´ì¤˜",
        "ë‹¬ì½¤í•˜ê³  ë¶€ë“œëŸ¬ìš´ ë¹µì„ íŒŒëŠ” ê³³ ì°¾ì•„ì¤˜",
        "ì‹œê·¸ë‹ˆì²˜ ë©”ë‰´ê°€ ìˆëŠ” ë¹µì§‘ ì–´ë”” ìˆì–´?",
    ]
    
    for query in example_queries:
        rag.chat(query, use_llm=True, use_openai=False)
        print("\n" + "-"*60 + "\n")
    
    # 4. ëŒ€í™”í˜• ëª¨ë“œ (ì„ íƒ)
    print("\nğŸ’¬ ëŒ€í™”í˜• ëª¨ë“œë¥¼ ì‹œì‘í•˜ë ¤ë©´ 'interactive' ëª¨ë“œë¡œ ì‹¤í–‰í•˜ì„¸ìš”.")
    print("   ì˜ˆ: python bakery_rag.py interactive")

def interactive_mode():
    """
    ëŒ€í™”í˜• ê²€ìƒ‰ ëª¨ë“œ
    """
    print(f"\n{'='*60}")
    print("ğŸ’¬ ëŒ€í™”í˜• ë¹µì§‘ ì¶”ì²œ ì‹œìŠ¤í…œ")
    print(f"{'='*60}\n")
    print("ğŸ’¡ ì‚¬ìš©ë²•: ì›í•˜ëŠ” ë¹µì´ë‚˜ íŠ¹ì§•ì„ ììœ ë¡­ê²Œ ì…ë ¥í•˜ì„¸ìš”.")
    print("   (ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ë˜ëŠ” 'exit' ì…ë ¥)\n")
    
    rag = BakeryRAGSystem()
    
    # ë°ì´í„° ë¡œë“œ í™•ì¸
    if rag.collection.count() == 0:
        print("âš ï¸ ë²¡í„° DBê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ ë¨¼ì € ì¸ë±ì‹±í•©ë‹ˆë‹¤...\n")
        rag.load_and_index_bakeries()
    
    while True:
        query = input("\nğŸ¤” ì§ˆë¬¸: ").strip()
        
        if query.lower() in ['quit', 'exit', 'ì¢…ë£Œ', 'q']:
            print("\nğŸ‘‹ ë¹µì§‘ ì¶”ì²œ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ë§›ìˆëŠ” ë¹µ ë“œì„¸ìš”!")
            break
        
        if not query:
            continue
        
        rag.chat(query, use_llm=True, use_openai=False)

if __name__ == '__main__':
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == 'interactive':
        interactive_mode()
    else:
        main()